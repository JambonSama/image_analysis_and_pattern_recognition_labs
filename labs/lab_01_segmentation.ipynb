{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR 2020:][iapr2020] Lab 1 â€’  Image segmentation\n",
    "\n",
    "**Authors:** Claire Meyer, Nicolas Furrer, Philipp Schuler  \n",
    "**Due date:** 26.03.2020\n",
    "\n",
    "[iapr2018]: https://github.com/LTS5/iapr-2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract relevant data\n",
    "We first need to extract the `lab-01-data.tar.gz` archive.\n",
    "To this end, we use the [tarfile] module from the Python standard library.\n",
    "\n",
    "[tarfile]: https://docs.python.org/3.6/library/tarfile.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "data_base_path = os.path.join(os.pardir, \"data\")\n",
    "data_folder = \"lab-01-data\"\n",
    "#tar_path = os.path.join(data_base_path, data_folder + '.tar.gz')\n",
    "#with tarfile.open(tar_path, mode='r:gz') as tar:\n",
    "#    tar.extractall(path=data_base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Brain segmentation\n",
    "\n",
    "Your goal: compute the size of the brain (in pixels) in a 2D image of a human head taken by Magnetic Resonance Imaging (MRI).\n",
    "* Try as many methods as you can, the more the better.\n",
    "* At least region growing and contour detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Brain image visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# Load image\n",
    "data_path = os.path.join(data_base_path, data_folder)\n",
    "brain_im = skimage.io.imread(os.path.join(data_path, \"brain-slice40.tiff\"))\n",
    "im_h, im_w = brain_im.shape\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(6, 6))\n",
    "ax.imshow(brain_im, cmap=\"gray\")\n",
    "ax.set_title(\"MRI brain image ({} px, {} px)\".format(im_h, im_w))\n",
    "ax.axis(\"off\")\n",
    "plt.show()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Region growing\n",
    "Add your implementation and discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_growing_openCV(image, seed, low_threshold, high_threshold):\n",
    "    mask = np.zeros((im_h+2,im_w+2),np.uint8)\n",
    "    cv.floodFill(image, mask, seed, 255,low_threshold, high_threshold)\n",
    "    return image, mask\n",
    "    \n",
    "\n",
    "\n",
    "brain_im_c = brain_im.copy()\n",
    "seed = (150,150)\n",
    "image, mask = region_growing_openCV(brain_im_c, seed, 6, 6)\n",
    "mask_h, mask_w = mask.shape\n",
    "count = 0\n",
    "for x in range(mask_w):\n",
    "    for y in range(mask_h):\n",
    "        if mask[x,y]==1:\n",
    "            count = count + 1\n",
    "\n",
    "\n",
    "#Plot\n",
    "print(\"Seed : \" , seed)\n",
    "print(\"Brain size : \", count, \" Pixels\")\n",
    "ax = plt.subplot(1,3,1)\n",
    "ax.set_title(\"Base image\")\n",
    "ax.imshow(brain_im, cmap='gray')\n",
    "ax.axis('off')\n",
    "ax = plt.subplot(1,3,2)\n",
    "ax.set_title(\"Brain detection\")\n",
    "ax.imshow(image, cmap='gray')\n",
    "ax.axis('off')\n",
    "ax = plt.subplot(1,3,3,)\n",
    "ax.set_title(\"Brain mask\")\n",
    "ax.imshow(mask, cmap ='gray')\n",
    "ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "Cest la la discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Contour detection\n",
    "Add your implementation and discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "# Image in open CV format\n",
    "original_img = cv.imread(os.path.join(data_path, \"brain-slice40.tiff\"),0)\n",
    "\n",
    "# # Histogram equalization \n",
    "# equalized_img = cv.equalizeHist(original_img)\n",
    "\n",
    "# Canny detection \n",
    "edges_img = cv.Canny(image=original_img,threshold1=85,threshold2=200,apertureSize=3)\n",
    "\n",
    "# Dilation of contours\n",
    "kernel = np.zeros((3,3),np.uint8)\n",
    "cv.circle(img=kernel, center=(1,1), radius=1, color=255, thickness=-1) \n",
    "dilated_edges_img = cv.dilate(edges_img,kernel,iterations = 1)\n",
    "\n",
    "# # Canny detection \n",
    "# t1 = 240\n",
    "# edges_img_2 = cv.Canny(image=equalized_img,threshold1=t1,threshold2=t1+5,apertureSize=3)\n",
    "\n",
    "# # Dilation of contours\n",
    "# dilated_edges_img_2 = cv.dilate(edges_img_2,kernel,iterations = 1)\n",
    "\n",
    "# Flood-filling from pixel (150, 150)\n",
    "h, w = edges_img.shape[:2]\n",
    "mask = np.zeros((h+2, w+2), np.uint8)\n",
    "flooded_img = dilated_edges_img.copy()\n",
    "cv.floodFill(flooded_img, mask, (150,150), 255);\n",
    "\n",
    "# Inversion of the flood filled image \n",
    "inverted_flooded_img = cv.bitwise_not(flooded_img)\n",
    "\n",
    "# Combination of the thresholded image with the inverted flood filled image using bitwise OR operation \n",
    "dilated_segmented_img = cv.bitwise_or(dilated_edges_img,inverted_flooded_img)\n",
    "segmented_img = cv.erode(dilated_segmented_img,kernel,iterations = 1)\n",
    "\n",
    "# Brain\n",
    "brain = cv.bitwise_not(segmented_img)\n",
    "superimposed_img = cv.add(src1=brain,src2=original_img)\n",
    "\n",
    "\n",
    "\n",
    "######################\n",
    "# ALREADY IN MASK\n",
    "######################\n",
    "\n",
    "\n",
    "# # Closing of contours\n",
    "# closed_edges_img = cv.morphologyEx(src=edges_img,op=cv.MORPH_CLOSE,kernel=kernel,iterations = 1)\n",
    "\n",
    "# # Flood-filling from pixel (150, 150)\n",
    "# mask_2 = np.zeros((h+2, w+2), np.uint8)\n",
    "# flooded_img_2 = closed_edges_img.copy()\n",
    "# cv.floodFill(flooded_img_2, mask_2, (150,150), 255);\n",
    "\n",
    "# # Inversion of the flood filled image \n",
    "# inverted_flooded_img_2 = cv.bitwise_not(flooded_img_2)\n",
    "\n",
    "# # Combination of the thresholded image with the inverted flood filled image using bitwise OR operation \n",
    "# segmented_img_2 = cv.bitwise_or(closed_edges_img,inverted_flooded_img_2)\n",
    "\n",
    "# Number of pixels\n",
    "n = np.sum(segmented_img == 255)\n",
    "print(f\"number of white pixels : {n}\")\n",
    "print(f\"proportion with respect to image size : {n/(256*256)}\")\n",
    "\n",
    "# Save \n",
    "# cv.imwrite(filename=\"test.png\", img=flooded_img_2)\n",
    "\n",
    "# Plots\n",
    "N = 3\n",
    "M = 3\n",
    "fig, ax = plt.subplots(N,M,figsize=(M*6,N*6))\n",
    "\n",
    "ax[0,0].imshow(original_img,cmap = 'gray')\n",
    "ax[0,0].set_title(\"Original image\")\n",
    "ax[0,1].imshow(edges_img,cmap = 'gray')\n",
    "ax[0,2].imshow(dilated_edges_img,cmap = 'gray')\n",
    "\n",
    "# ax[1,0].imshow(closed_edges_img,cmap = 'gray')\n",
    "# ax[1,1].imshow(mask_2,cmap = 'gray')\n",
    "# ax[1,2].imshow(cv.bitwise_not(segmented_img_2),cmap = 'gray')\n",
    "\n",
    "ax[1,0].imshow(flooded_img,cmap = 'gray')\n",
    "ax[1,1].imshow(inverted_flooded_img,cmap = 'gray')\n",
    "ax[1,2].imshow(dilated_segmented_img,cmap = 'gray')\n",
    "\n",
    "ax[2,0].imshow(segmented_img,cmap = 'gray')\n",
    "ax[2,1].imshow(brain,cmap = 'gray')\n",
    "ax[2,2].imshow(superimposed_img,cmap = 'gray')\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Additional method(s)\n",
    "Add your implementation and discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Shape/color segmentation\n",
    "\n",
    "You will find hereafter three pictures taken under three different illuminations, containing some shapes with different colors. We ask you to create a routine to:\n",
    "\n",
    "1. Count the number of shapes of each color.\n",
    "2. Compute the total area (in pixels) of each color.\n",
    "\n",
    "Please note that one specific challenge is to be robust to illumination changes. Therefore some kind of intensity normalization should probably be used.\n",
    "\n",
    "**Note:** the routine(s) that you will write for this exercise will be useful for the final project as well, so pay special attention to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "im_names = ['arena-shapes-01', 'arena-shapes-02', 'arena-shapes-03']\n",
    "filenames = [os.path.join(data_path, name) + '.png' for name in im_names]\n",
    "ic = skimage.io.imread_collection(filenames)\n",
    "images = skimage.io.concatenate_images(ic)\n",
    "print('Number of images: ', images.shape[0])\n",
    "print('Image size: {}, {} '.format(images.shape[1], images.shape[2]))\n",
    "print('Number of color channels: ', images.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 12))\n",
    "for ax, im, nm in zip(axes.ravel(), images, im_names):\n",
    "    ax.imshow(im)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Number of shapes of each color\n",
    "Add your implementation and discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Total area (in pixels) of each color\n",
    "Add your implementation and discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"area 1 = {stats[0][cv.CC_STAT_AREA]}\")\n",
    "print(f\"area 2 = {stats[1][cv.CC_STAT_AREA]}\")\n",
    "print(f\"proportion = {stats[0][cv.CC_STAT_AREA]/stats[1][cv.CC_STAT_AREA]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)\n",
    "\n",
    "dt = 0.01\n",
    "t = np.arange(0, 30, dt)\n",
    "nse1 = np.random.randn(len(t))                 # white noise 1\n",
    "nse2 = np.random.randn(len(t))                 # white noise 2\n",
    "\n",
    "# Two signals with a coherent part at 10Hz and a random part\n",
    "s1 = np.sin(2 * np.pi * 10 * t) + nse1\n",
    "s2 = np.sin(2 * np.pi * 10 * t) + nse2\n",
    "\n",
    "fig, axs = plt.subplots(2, 1)\n",
    "axs[0].plot(t, s1, t, s2)\n",
    "axs[0].set_xlim(0, 2)\n",
    "axs[0].set_xlabel('time')\n",
    "axs[0].set_ylabel('s1 and s2')\n",
    "axs[0].grid(True)\n",
    "\n",
    "cxy, f = axs[1].cohere(s1, s2, 256, 1. / dt)\n",
    "axs[1].set_ylabel('coherence')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
