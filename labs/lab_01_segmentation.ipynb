{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR 2020:][iapr2020] Lab 1 â€’  Image segmentation\n",
    "\n",
    "**Authors:** Claire Meyer, Nicolas Furrer, Philipp Schuler  \n",
    "**Due date:** 26.03.2020\n",
    "\n",
    "[iapr2018]: https://github.com/LTS5/iapr-2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract relevant data\n",
    "We first need to extract the `lab-01-data.tar.gz` archive.\n",
    "To this end, we use the [tarfile] module from the Python standard library.\n",
    "\n",
    "[tarfile]: https://docs.python.org/3.6/library/tarfile.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "data_base_path = os.path.join(os.pardir, \"data\")\n",
    "data_folder = \"lab-01-data\"\n",
    "#tar_path = os.path.join(data_base_path, data_folder + '.tar.gz')\n",
    "#with tarfile.open(tar_path, mode='r:gz') as tar:\n",
    "#    tar.extractall(path=data_base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Brain segmentation\n",
    "\n",
    "Your goal: compute the size of the brain (in pixels) in a 2D image of a human head taken by Magnetic Resonance Imaging (MRI).\n",
    "* Try as many methods as you can, the more the better.\n",
    "* At least region growing and contour detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Brain image visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# Load image with OpenCV\n",
    "data_path = os.path.join(data_base_path, data_folder)\n",
    "original_img = cv.imread(os.path.join(data_path, \"brain-slice40.tiff\"),0)\n",
    "height, width = original_img.shape[:2]\n",
    "\n",
    "# Plot image\n",
    "M = 1\n",
    "N = 1\n",
    "size = 6\n",
    "fig, ax = plt.subplots(N,M,figsize=(M*size,N*size))\n",
    "ax.imshow(original_img, cmap=\"gray\")\n",
    "ax.set_title(\"MRI brain image ({} px, {} px)\".format(height,width))\n",
    "ax.axis(\"off\")\n",
    "\n",
    "#End of cell\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Region growing\n",
    "Add your implementation and discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_growing(image, seed, low_threshold, high_threshold):\n",
    "    mask = np.zeros((height+2,width+2),np.uint8)\n",
    "    cv.floodFill(image, mask, seed, 255,low_threshold, high_threshold)\n",
    "    return image, mask\n",
    "    \n",
    "\n",
    "\n",
    "brain_im_c = original_img.copy()\n",
    "seed = (150,150)\n",
    "image, mask = region_growing(brain_im_c, seed, 6, 6)\n",
    "mask_h, mask_w = mask.shape\n",
    "count = 0\n",
    "for x in range(mask_w):\n",
    "    for y in range(mask_h):\n",
    "        if mask[x,y]==1:\n",
    "            count = count + 1\n",
    "\n",
    "\n",
    "#Plot\n",
    "print(\"Seed : \" , seed)\n",
    "print(\"Brain size : \", count, \" Pixels\")\n",
    "ax = plt.subplot(1,3,1)\n",
    "ax.set_title(\"Base image\")\n",
    "ax.imshow(original_img, cmap='gray')\n",
    "ax.axis('off')\n",
    "ax = plt.subplot(1,3,2)\n",
    "ax.set_title(\"Brain detection\")\n",
    "ax.imshow(image, cmap='gray')\n",
    "ax.axis('off')\n",
    "ax = plt.subplot(1,3,3,)\n",
    "ax.set_title(\"Brain mask\")\n",
    "ax.imshow(mask, cmap ='gray')\n",
    "ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "Cest la la discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Contour detection\n",
    "<!-- Add your implementation and discussion -->\n",
    "\n",
    "In order to compute the size of the brain using contour detection, we start from the original image, $I_1$, and compute the subsequent images :\n",
    "- $I_2$, by applying the Canny algorithm on $I_1$, the original image. We obtain the contours of the original image.\n",
    "- $I_3$, by dilating $I_2$, the contours. We obtained closed contours.\n",
    "- $I_4$, by flood-filling $I_3$, the closed contours, with a initial seed in the brain. We obtain a compound black image, with the closed dilated contours and the brain surface in white.\n",
    "- $I_5$, by performing the \"NOT\" bitwise operation on $I_4$. We obtain a compound white image, with the closed dilated contours and the brain surface in black.\n",
    "- $I_6$, by performing the \"OR\" bitwise operation on $I_3$ and $I_5$. Since $I_3$ contains the closed dilated contours, and $I_5$ anything but the contours and the brain surface, we obtain a white image with the brain surface in black, except the edges of the brain, which are white because of the previous dilation.\n",
    "- $I_7$, by eroding $I_6$. We obtain a white image with the brain in black, but this time the correct surface.\n",
    "- $I_8$, by performing the \"NOT\" bitwise operation on $I_7$. We obtain a mask of the brain surface.\n",
    "\n",
    "From there, we just count how many pixels are white in $I_8$, the mask, to have the size of the brain in pixels. To verify the quality of the result, we also compute $I_9$, by superimposing $I_8$, the mask of the brain, on $I_1$, the original image. It allows us to assess that the brain surface is indeed correct.\n",
    "\n",
    "<br>\n",
    "\n",
    "All the steps from the original image to the brain mask and the quality control image (from $I_1$ to $I_9$) are displayed below, along with the implementation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny detection \n",
    "t1 = 85\n",
    "t2 = 200\n",
    "edges_img = cv.Canny(image=original_img, threshold1=t1, threshold2=t2, apertureSize=3)\n",
    "\n",
    "# Dilation of contours\n",
    "kernel = np.zeros((3,3), np.uint8)\n",
    "cv.circle(img=kernel, center=(1,1), radius=1, color=255, thickness=-1) \n",
    "dilated_edges_img = cv.dilate(edges_img, kernel, iterations=1)\n",
    "\n",
    "# Flood-filling from pixel (150, 150)\n",
    "mask = np.zeros((height+2, width+2), np.uint8)\n",
    "flooded_img = dilated_edges_img.copy()\n",
    "cv.floodFill(flooded_img, mask, (150,150), 255);\n",
    "\n",
    "# Inversion of the flood filled image \n",
    "inverted_flooded_img = cv.bitwise_not(flooded_img)\n",
    "\n",
    "# Combination of the thresholded image with the inverted flood filled image using bitwise OR operation \n",
    "dilated_segmented_img = cv.bitwise_or(dilated_edges_img, inverted_flooded_img)\n",
    "segmented_img = cv.erode(dilated_segmented_img, kernel, iterations=1)\n",
    "\n",
    "# Brain mask\n",
    "brain_mask = cv.bitwise_not(segmented_img)\n",
    "\n",
    "# Superimposition\n",
    "empty_mask = np.zeros((height, width), np.uint8)\n",
    "color_brain_mask = cv.merge(mv=(empty_mask, empty_mask, brain_mask))\n",
    "color_original_img = cv.cvtColor(original_img, code=cv.COLOR_GRAY2RGB)\n",
    "superimposed_img = cv.add(src1=color_brain_mask, src2=color_original_img)\n",
    "\n",
    "# Number of pixels\n",
    "n = np.sum(brain == 255)\n",
    "print(f\"{n} white pixels in the {height}x{width} image.\")\n",
    "print(f\"Percentage of white pixels in the image : {n*100/(width*height):.2f}%\")\n",
    "\n",
    "# Plots\n",
    "M = 3\n",
    "N = 3\n",
    "fig, ax = plt.subplots(N, M, figsize=(M*size, N*size))\n",
    "\n",
    "ax[0,0].imshow(original_img, cmap = 'gray')\n",
    "ax[0,0].set_title(\"$I_1$ : Original image\")\n",
    "ax[0,1].imshow(edges_img, cmap = 'gray')\n",
    "ax[0,1].set_title(\"$I_2$ : Contours of original image\")\n",
    "ax[0,2].imshow(dilated_edges_img, cmap = 'gray')\n",
    "ax[0,2].set_title(\"$I_3$ : Closed, dilated contours\")\n",
    "\n",
    "ax[1,0].imshow(flooded_img, cmap = 'gray')\n",
    "ax[1,0].set_title(\"$I_4$ : Closed, dilated contours and brain surface in white\")\n",
    "ax[1,1].imshow(inverted_flooded_img, cmap = 'gray')\n",
    "ax[1,1].set_title(\"$I_5$ : Closed, dilated contours and brain surface in black\")\n",
    "ax[1,2].imshow(dilated_segmented_img, cmap = 'gray')\n",
    "ax[1,2].set_title(\"$I_6$ : Mask of everything but brain surface\")\n",
    "\n",
    "ax[2,0].imshow(segmented_img, cmap = 'gray')\n",
    "ax[2,0].set_title(\"$I_7$ : Mask of brain surface, but smaller\")\n",
    "ax[2,1].imshow(brain_mask, cmap = 'gray')\n",
    "ax[2,1].set_title(\"$I_8$ : Mask of brain surface\")\n",
    "ax[2,2].imshow(superimposed_img, cmap = 'gray')\n",
    "ax[2,2].set_title(\"$I_9$ : Control image (mask on original image)\")\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.axis(\"off\")\n",
    "\n",
    "#End of cell\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result indicates that the surface of the brain is of 15742 px, which corresponds to 24.02% of the image size, as can be seen just above. $I_9$, the quality control image, also shows that the segmentation is good, and thus that the result can be trusted.\n",
    "\n",
    "<br>\n",
    "\n",
    "This method requires a few meta parameters :\n",
    "- $t_1$ and $t_2$, the thresholds for the Canny edges detector. Those two threshold mark the strong and weak edges : anything above the highest threshold is a strong edge, anything below the lowest threshold is deleted, and the rest is a weak edge, whose validity is determined by its link, or lack thereof, to a strong edge. Those values are determined empirically, and influence drastically the result of the edge detection. Here, we chose $t_1$=85 and $t_2$=200.\n",
    "- The dilation kernel $K$ is also quite important. If too small, the dilation doesn't close the edges. If too big, some edges that should remain separate become fused. Here, the kernel is a circle of radius 1, which is equivalent to a cross on a 3x3 matrix. To ensure some degree of consistency, the same kernel is used for the subsequent erosion.\n",
    "- Similarly, the dilation iteration number, if too high, can fuse edges that should remain separate. Here, we only iterated the dilation once; and thus we only eroded once as well, for consistency.\n",
    "- The flood-fill necessitates an initial seed, to begin the the flood-filling from. In order to find the surface of the brain, that seed needs to be located somewhere within that area. Thus, it can take many values, as long as the coordinates are within the surface of the brain. Here, they were chosen by estimation with the naked eye (trial and error), and ($x$,$y$)=(150,150) is such a coordinate.\n",
    "\n",
    "<br>\n",
    "\n",
    "Initially, we tried an histogram equalization on the original image, to see if we could determine the edges more acurately that way. It proved to be severely unhelpful, to the point of being deleterious to the result. When looking at the result of an histogram equalization, we can easily see why. Indeed a lot of noise is enhanced by the equalization, to the point where there are way too many false positive when trying to detect the edges with the Canny algorithm. Below are shown the original image, the histogram equalization of that original image, and the edges detected with the Canny algorithm from that equalized image :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram equalization \n",
    "equalized_img = cv.equalizeHist(original_img)\n",
    "\n",
    "# Canny detection \n",
    "t1 = 240\n",
    "t2 = 245\n",
    "edges_img_2 = cv.Canny(image=equalized_img,threshold1=t1,threshold2=t2,apertureSize=3)\n",
    "\n",
    "# Plots\n",
    "M = 3\n",
    "N = 1\n",
    "fig, ax = plt.subplots(N, M, figsize=(M*size, N*size))\n",
    "\n",
    "ax[0].imshow(original_img, cmap = 'gray')\n",
    "ax[0].set_title(\"Original image\")\n",
    "ax[1].imshow(equalized_img, cmap = 'gray')\n",
    "ax[1].set_title(\"Equalized original image\")\n",
    "ax[2].imshow(edges_img_2, cmap = 'gray')\n",
    "ax[2].set_title(\"Contours detected on equalized image\")\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.axis(\"off\")\n",
    "\n",
    "#End of cell\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to try and detect only the strongest edges, the Canny thresholds are set very high, to keep only the strongest of edges, but that is still way too many edges; there are a lot of false positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Additional method(s)\n",
    "Add your implementation and discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Shape/color segmentation\n",
    "\n",
    "You will find hereafter three pictures taken under three different illuminations, containing some shapes with different colors. We ask you to create a routine to:\n",
    "\n",
    "1. Count the number of shapes of each color.\n",
    "2. Compute the total area (in pixels) of each color.\n",
    "\n",
    "Please note that one specific challenge is to be robust to illumination changes. Therefore some kind of intensity normalization should probably be used.\n",
    "\n",
    "**Note:** the routine(s) that you will write for this exercise will be useful for the final project as well, so pay special attention to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "im_names = ['arena-shapes-01', 'arena-shapes-02', 'arena-shapes-03']\n",
    "filenames = [os.path.join(data_path, name) + '.png' for name in im_names]\n",
    "ic = skimage.io.imread_collection(filenames)\n",
    "images = skimage.io.concatenate_images(ic)\n",
    "print('Number of images: ', images.shape[0])\n",
    "print('Image size: {}, {} '.format(images.shape[1], images.shape[2]))\n",
    "print('Number of color channels: ', images.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 12))\n",
    "for ax, im, nm in zip(axes.ravel(), images, im_names):\n",
    "    ax.imshow(im)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Number of shapes of each color\n",
    "Add your implementation and discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Total area (in pixels) of each color\n",
    "Add your implementation and discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"area 1 = {stats[0][cv.CC_STAT_AREA]}\")\n",
    "print(f\"area 2 = {stats[1][cv.CC_STAT_AREA]}\")\n",
    "print(f\"proportion = {stats[0][cv.CC_STAT_AREA]/stats[1][cv.CC_STAT_AREA]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)\n",
    "\n",
    "dt = 0.01\n",
    "t = np.arange(0, 30, dt)\n",
    "nse1 = np.random.randn(len(t))                 # white noise 1\n",
    "nse2 = np.random.randn(len(t))                 # white noise 2\n",
    "\n",
    "# Two signals with a coherent part at 10Hz and a random part\n",
    "s1 = np.sin(2 * np.pi * 10 * t) + nse1\n",
    "s2 = np.sin(2 * np.pi * 10 * t) + nse2\n",
    "\n",
    "fig, axs = plt.subplots(2, 1)\n",
    "axs[0].plot(t, s1, t, s2)\n",
    "axs[0].set_xlim(0, 2)\n",
    "axs[0].set_xlabel('time')\n",
    "axs[0].set_ylabel('s1 and s2')\n",
    "axs[0].grid(True)\n",
    "\n",
    "cxy, f = axs[1].cohere(s1, s2, 256, 1. / dt)\n",
    "axs[1].set_ylabel('coherence')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
