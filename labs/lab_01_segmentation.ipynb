{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR 2020:][iapr2020] Lab 1 â€’  Image segmentation\n",
    "\n",
    "**Authors:** Claire Meyer, Nicolas Furrer, Philipp Schuler  \n",
    "**Due date:** 26.03.2020\n",
    "\n",
    "[iapr2020]: https://github.com/LTS5/iapr-2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting relevant data\n",
    "We first need to extract the `lab-01-data.tar.gz` archive.\n",
    "To this end, we use the [tarfile] module from the Python standard library.\n",
    "\n",
    "[tarfile]: https://docs.python.org/3.6/library/tarfile.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "data_base_path = os.path.join(os.pardir, \"data\")\n",
    "data_folder = \"lab-01-data\"\n",
    "#tar_path = os.path.join(data_base_path, data_folder + '.tar.gz')\n",
    "#with tarfile.open(tar_path, mode='r:gz') as tar:\n",
    "#    tar.extractall(path=data_base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Brain segmentation\n",
    "\n",
    "Your goal: compute the size of the brain (in pixels) in a 2D image of a human head taken by Magnetic Resonance Imaging (MRI).\n",
    "* Try as many methods as you can, the more the better.\n",
    "* At least region growing and contour detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Brain image visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# Load image with OpenCV\n",
    "data_path = os.path.join(data_base_path, data_folder)\n",
    "original_img = cv.imread(os.path.join(data_path, \"brain-slice40.tiff\"),0)\n",
    "height, width = original_img.shape[:2]\n",
    "\n",
    "# Plot image\n",
    "n_lin = 1\n",
    "n_col = 1\n",
    "size = 6\n",
    "fig, ax = plt.subplots(n_lin, n_col, figsize=(n_col*size, n_lin*size))\n",
    "ax.imshow(original_img, cmap=\"gray\")\n",
    "ax.set_title(\"MRI brain image ({} px, {} px)\".format(height,width))\n",
    "ax.axis(\"off\")\n",
    "\n",
    "#End of cell\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Region growing\n",
    "<!-- Add your implementation and discussion -->\n",
    "\n",
    "In order to compute the size of the brain using region growing, we start from the original image, $I_1$, and compute the subsequent images :\n",
    "- $I_2$, by doing region growing on $I_1$, the original image. We obtain the original image superimposed with the mask of the brain surface. The OpenCV function used, `cv.floodFill(image, mask, seedPoint, newVal, loDiff, upDiff)`, also fill the argument `mask` with the mask of the brain surface, but that mask is bigger than the original image (if original image is $n$ x $n$, then the mask is ($n$+2) x ($n$+2), and the padding is filled with the filling value, so here, white (255).\n",
    "- $I_3$, by cropping the mask obtained at the previous steop. We just need to remove the aforementionned padding. We obtain a mask of the brain surface (brain surface is white on black background).\n",
    "\n",
    "From there, we just count how many pixels are white in $I_3$, the mask, to have the size of the brain in pixels. To verify the quality of the result, we also compute $I_4$, by superimposing $I_3$, the mask of the brain, on $I_1$, the original image. It allows us to assess that the brain surface is indeed correct with visual proof.\n",
    "\n",
    "<br>\n",
    "\n",
    "All the steps from the original image to the brain mask and the quality control image (from $I_1$ to $I_4$) are displayed below, along with the implementation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region growing from pixel (150,150)\n",
    "grown_img = original_img.copy()\n",
    "seed = (150,150)\n",
    "t1 = 6\n",
    "t2 = 15\n",
    "mask = np.zeros((height+2,width+2), np.uint8)\n",
    "cv.floodFill(image=grown_img, mask=mask, seedPoint=seed, newVal=255, loDiff=t1, upDiff=t2)\n",
    "\n",
    "# Getting the mask back\n",
    "brain_mask = mask[1:width+1,1:height+1].copy()*255\n",
    "cv.imwrite(filename=\"test.png\", img=brain_mask)\n",
    "\n",
    "# Superimposition\n",
    "empty_mask = np.zeros((height, width), np.uint8)\n",
    "color_brain_mask = cv.merge(mv=(empty_mask, empty_mask, brain_mask))\n",
    "color_original_img = cv.cvtColor(original_img, code=cv.COLOR_GRAY2RGB)\n",
    "superimposed_img = cv.add(src1=color_brain_mask, src2=color_original_img)\n",
    "\n",
    "# Number of pixels\n",
    "n = np.sum(brain_mask == 255)\n",
    "\n",
    "# Hyperparameters :\n",
    "print(f\"Hyperparamters : \")\n",
    "print(f\"    Seed at {seed}.\")\n",
    "print(f\"    Max lower difference : {t1}.\")\n",
    "print(f\"    Max upper difference : {t2}.\")\n",
    "\n",
    "# Results\n",
    "print(f\"Results : \")\n",
    "print(f\"    Size of the brain : {n} px in the {height}x{width} image.\")\n",
    "print(f\"    Percentage of area occupied by the brain in the image : {n*100/(width*height):.2f}%.\")\n",
    "\n",
    "# Plots\n",
    "n_lin = 2\n",
    "n_col = 2\n",
    "fig, ax = plt.subplots(n_lin, n_col, figsize=(n_col*size, n_lin*size))\n",
    "\n",
    "ax[0,0].imshow(original_img, cmap = 'gray')\n",
    "ax[0,0].set_title(\"$I_1$ : Original image\")\n",
    "\n",
    "ax[0,1].imshow(grown_img, cmap = 'gray')\n",
    "ax[0,1].set_title(\"$I_2$ : Region growing result\")\n",
    "\n",
    "ax[1,0].imshow(brain_mask, cmap = 'gray')\n",
    "ax[1,0].set_title(\"$I_3$ : Mask of brain surface\")\n",
    "\n",
    "ax[1,1].imshow(superimposed_img, cmap = 'gray')\n",
    "ax[1,1].set_title(\"$I_4$ : Control image (mask on original image)\")\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.axis(\"off\")\n",
    "\n",
    "#End of cell\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result indicates that the surface of the brain is of 15667 px, which corresponds to 23.91% of the image size, as can be seen just above. $I_4$, the quality control image, also shows that the segmentation is good, and thus that the result can be trusted.\n",
    "\n",
    "<br>\n",
    "\n",
    "This method requires three meta parameters :\n",
    "- An initial seed for the region growing, to begin the the flood-filling from. In order to find the surface of the brain, that seed needs to be located somewhere within that area. Thus, it can take many values, as long as the coordinates are within the surface of the brain. Here, they were chosen by estimation with the naked eye (trial and error), and ($x$,$y$)=(150,150) is such a coordinate.\n",
    "- A lower and upper brightness difference beetween the currently observed pixel (pixel at $(x,y)$) and one of its neighbors belonging to the component, or a seed pixel being added to the component (pixel at $(x',y')$). Here, we determine that the next pixel belong to the region if :\n",
    "    $$\\texttt{src} (x',y')- \\texttt{loDiff} \\leq \\texttt{src} (x,y) \\leq \\texttt{src} (x',y')+ \\texttt{upDiff}$$\n",
    "    Here, the lower difference is 6, and the upper difference is 15. It means that a pixel is much more easily added to the growing region if the brightness is higher, than if the brightness is lower, as the empty zones between the brain and the skull are darker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Contour detection\n",
    "<!-- Add your implementation and discussion -->\n",
    "\n",
    "In order to compute the size of the brain using contour detection, we start from the original image, $I_1$, and compute the subsequent images :\n",
    "- $I_2$, by applying the Canny algorithm on $I_1$, the original image. We obtain the contours of the original image. But those contours are not closed, they are just edges from the original image. To determine a region (here, the brain), we need the contour around that region closed (the other contours don't matter).\n",
    "- $I_3$, by dilating $I_2$, the contours. We obtained closed contours, because the dilation of the contours make them grow. Thus, the area containing the brain is determined by a closed contour.\n",
    "- $I_4$, by flooding $I_3$, the closed contours, with a initial seed in the brain. We obtain a compound black image, with the closed dilated contours and the brain surface in white. Indeed, flooding fills a zone on the basis of a continuous color (or here, lack thereof, because we flood an area of pixel value 0). Because we fill from the inside of the brain (black), and the brain is closed by closed contours (white), after flood-filling, the brain is white. It is the same function from OpenCV than the one used in the region growing part; but the difference is that here, we do not set the lower and upper difference. Thus they are the default, which is 0. It means that it is no longer a region growing, but a flooding (only exactly the same color is filled).\n",
    "- $I_5$, by performing the \"NOT\" bitwise operation on $I_4$. We obtain a compound white image, with the closed dilated contours and the brain surface in black. The operations to obtain $I_5$ and $I_6$ are just logical operations on the images, to obtain what we want.\n",
    "- $I_6$, by performing the \"OR\" bitwise operation on $I_3$ and $I_5$. Since $I_3$ contains the closed dilated contours, and $I_5$ anything but the contours and the brain surface, we obtain a white image with the brain surface in black. That brain surface is eroded compared to the real size, because of the previous dilation (of the edges of the brain).\n",
    "- $I_7$, by eroding $I_6$. We obtain a white image with the brain in black, but this time the correct surface. We need this erosion because we had to dilate $I_2$, to close the contours. This dilation \"ate away\" at the brain, so now we need to \"grow it back up\". This is done by erosion because the brain is in black, not in white. \n",
    "- $I_8$, by performing the \"NOT\" bitwise operation on $I_7$. We obtain a mask of the brain surface (brain surface is white on black background).\n",
    "\n",
    "From there, we just count how many pixels are white in $I_8$, the mask, to have the size of the brain in pixels. To verify the quality of the result, we also compute $I_9$, by superimposing $I_8$, the mask of the brain, on $I_1$, the original image. It allows us to assess that the brain surface is indeed correct with visual proof.\n",
    "\n",
    "<br>\n",
    "\n",
    "All the steps from the original image to the brain mask and the quality control image (from $I_1$ to $I_9$) are displayed below, along with the implementation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny detection \n",
    "t1 = 85\n",
    "t2 = 200\n",
    "edges_img = cv.Canny(image=original_img, threshold1=t1, threshold2=t2, apertureSize=3)\n",
    "\n",
    "# Dilation of contours\n",
    "kernel = np.zeros((3,3), np.uint8)\n",
    "cv.circle(img=kernel, center=(1,1), radius=1, color=255, thickness=-1) \n",
    "dilated_edges_img = cv.dilate(edges_img, kernel, iterations=1)\n",
    "\n",
    "# Flood-filling from pixel (150, 150)\n",
    "mask = np.zeros((height+2, width+2), np.uint8)\n",
    "flooded_img = dilated_edges_img.copy()\n",
    "seed = (150,150)\n",
    "cv.floodFill(flooded_img, mask, seed, 255);\n",
    "\n",
    "# Inversion of the flood filled image \n",
    "inverted_flooded_img = cv.bitwise_not(flooded_img)\n",
    "\n",
    "# Combination of the thresholded image with the inverted flood filled image using bitwise OR operation \n",
    "dilated_segmented_img = cv.bitwise_or(dilated_edges_img, inverted_flooded_img)\n",
    "segmented_img = cv.erode(dilated_segmented_img, kernel, iterations=1)\n",
    "\n",
    "# Brain mask\n",
    "brain_mask = cv.bitwise_not(segmented_img)\n",
    "\n",
    "# Superimposition\n",
    "empty_mask = np.zeros((height, width), np.uint8)\n",
    "color_brain_mask = cv.merge(mv=(empty_mask, empty_mask, brain_mask))\n",
    "color_original_img = cv.cvtColor(original_img, code=cv.COLOR_GRAY2RGB)\n",
    "superimposed_img = cv.add(src1=color_brain_mask, src2=color_original_img)\n",
    "\n",
    "# Number of pixels\n",
    "n = np.sum(brain_mask == 255)\n",
    "\n",
    "# Hyperparameters :\n",
    "print(f\"Hyperparamters : \")\n",
    "print(f\"    Low Canny threshold : {t1}.\")\n",
    "print(f\"    High Canny threshold : {t2}.\")\n",
    "print(f\"    Seed at {seed}.\")\n",
    "\n",
    "# Results\n",
    "print(f\"Results : \")\n",
    "print(f\"    Size of the brain : {n} px in the {height}x{width} image.\")\n",
    "print(f\"    Percentage of area occupied by the brain in the image : {n*100/(width*height):.2f}%.\")\n",
    "\n",
    "# Plots\n",
    "n_lin = 3\n",
    "n_col = 3\n",
    "fig, ax = plt.subplots(n_lin, n_col, figsize=(n_col*size, n_lin*size))\n",
    "\n",
    "ax[0,0].imshow(original_img, cmap = 'gray')\n",
    "ax[0,0].set_title(\"$I_1$ : Original image\")\n",
    "\n",
    "ax[0,1].imshow(edges_img, cmap = 'gray')\n",
    "ax[0,1].set_title(\"$I_2$ : Contours of original image\")\n",
    "\n",
    "ax[0,2].imshow(dilated_edges_img, cmap = 'gray')\n",
    "ax[0,2].set_title(\"$I_3$ : Closed, dilated contours\")\n",
    "\n",
    "ax[1,0].imshow(flooded_img, cmap = 'gray')\n",
    "ax[1,0].set_title(\"$I_4$ : Closed, dilated contours and brain surface in white\")\n",
    "\n",
    "ax[1,1].imshow(inverted_flooded_img, cmap = 'gray')\n",
    "ax[1,1].set_title(\"$I_5$ : Closed, dilated contours and brain surface in black\")\n",
    "\n",
    "ax[1,2].imshow(dilated_segmented_img, cmap = 'gray')\n",
    "ax[1,2].set_title(\"$I_6$ : Mask of everything but brain \\n(the brain is a little bit eroded away\\nbecause of the dilation at the third step)\")\n",
    "\n",
    "ax[2,0].imshow(segmented_img, cmap = 'gray')\n",
    "ax[2,0].set_title(\"$I_7$ : Mask of brain surface (inverted)\")\n",
    "\n",
    "ax[2,1].imshow(brain_mask, cmap = 'gray')\n",
    "ax[2,1].set_title(\"$I_8$ : Mask of brain surface\")\n",
    "\n",
    "ax[2,2].imshow(superimposed_img, cmap = 'gray')\n",
    "ax[2,2].set_title(\"$I_9$ : Control image (mask on original image)\")\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.axis(\"off\")\n",
    "\n",
    "#End of cell\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result indicates that the surface of the brain is of 15742 px, which corresponds to 24.02% of the image size, as can be seen just above. $I_9$, the quality control image, also shows that the segmentation is good, and thus that the result can be trusted.\n",
    "\n",
    "<br>\n",
    "\n",
    "This method requires a few meta parameters :\n",
    "- $t_1$ and $t_2$, the thresholds for the Canny edges detector. Those two threshold mark the strong and weak edges : anything above the highest threshold is a strong edge, anything below the lowest threshold is deleted, and the rest is a weak edge, whose validity is determined by its link, or lack thereof, to a strong edge. Those values are determined empirically, and influence drastically the result of the edge detection. Here, we chose $t_1$=85 and $t_2$=200.\n",
    "- The dilation kernel is also quite important. If too small, the dilation doesn't close the edges. If too big, some edges that should remain separate become fused. Here, the kernel is a circle of radius 1, which is equivalent to a cross on a 3x3 matrix. To ensure some degree of consistency, the same kernel is used for the subsequent erosion.\n",
    "- Similarly, the dilation iteration number, if too high, can fuse edges that should remain separate. Here, we only iterated the dilation once; and thus we only eroded once as well, for consistency.\n",
    "- The flooding necessitates an initial seed, to begin the the flooding from. In order to find the surface of the brain, that seed needs to be located somewhere within that area. Thus, it can take many values, as long as the coordinates are within the surface of the brain. Here, they were chosen by estimation with the naked eye (trial and error), and ($x$,$y$)=(150,150) is such a coordinate.\n",
    "\n",
    "<br>\n",
    "\n",
    "Initially, we tried an histogram equalization on the original image, to see if we could determine the edges more acurately that way. It proved to be severely unhelpful, to the point of being deleterious to the result. When looking at the result of an histogram equalization, we can easily see why. Indeed a lot of noise is enhanced by the equalization, to the point where there are way too many false positive when trying to detect the edges with the Canny algorithm. Below are shown the original image, the histogram equalization of that original image, and the edges detected with the Canny algorithm from that equalized image :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram equalization \n",
    "equalized_img = cv.equalizeHist(original_img)\n",
    "\n",
    "# Canny detection \n",
    "t1 = 240\n",
    "t2 = 245\n",
    "edges_img_2 = cv.Canny(image=equalized_img,threshold1=t1,threshold2=t2,apertureSize=3)\n",
    "\n",
    "# Plots\n",
    "n_lin = 1\n",
    "n_col = 3\n",
    "fig, ax = plt.subplots(n_lin, n_col, figsize=(n_col*size, n_lin*size))\n",
    "\n",
    "ax[0].imshow(original_img, cmap = 'gray')\n",
    "ax[0].set_title(\"Original image\")\n",
    "\n",
    "ax[1].imshow(equalized_img, cmap = 'gray')\n",
    "ax[1].set_title(\"Equalized original image\")\n",
    "\n",
    "ax[2].imshow(edges_img_2, cmap = 'gray')\n",
    "ax[2].set_title(\"Contours detected on equalized image\")\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.axis(\"off\")\n",
    "\n",
    "#End of cell\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to try and detect only the strongest edges, the Canny thresholds are set very high, to keep only the strongest of edges, but there are still too many false positive : the histogram equalization broke the edges on the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Active contours\n",
    "<!-- Add your implementation and discussion -->\n",
    "\n",
    "In order to compute the size of the brain using active contours, we initialize an initial snake around the brain, and then warp it to closely stick to the brain surface edge. From it, we compute the area within the snake using the Green theorem.\n",
    "\n",
    "<br>\n",
    "\n",
    "All the steps are displayed below, along with the implementation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import gaussian\n",
    "from skimage.segmentation import active_contour\n",
    "\n",
    "# Area calculation with green theorem :\n",
    "# Source: https://stackoverflow.com/questions/22678990/how-can-i-calculate-the-area-within-a-contour-in-python-using-the-matplotlib\n",
    "def area(vs):\n",
    "    area = 0\n",
    "    x0,y0 = vs[0]\n",
    "    for [x1,y1] in vs[1:]:\n",
    "        dx = x1-x0\n",
    "        dy = y1-y0\n",
    "        area += 0.5*(y0*dx - x0*dy)\n",
    "        x0 = x1\n",
    "        y0 = y1\n",
    "    return area\n",
    "\n",
    "# Initialisation of the snake as a circle centered around the brain\n",
    "center = (147, 125)\n",
    "radius = 75\n",
    "samples = np.linspace(0, 2*np.pi, 400)\n",
    "sine = center[0] + radius*np.sin(samples)\n",
    "cosine = center[1] + radius*np.cos(samples)\n",
    "initial_snake = np.array([sine, cosine]).T\n",
    "\n",
    "# Gaussian blur\n",
    "blurred_img = gaussian(original_img, 1)\n",
    "\n",
    "# Active contour detection \n",
    "beta_val = 4\n",
    "line_val = -5\n",
    "edge_val = 10\n",
    "final_snake_original = active_contour(original_img, initial_snake, beta=beta_val, w_line=line_val, w_edge=edge_val, coordinates='rc')\n",
    "\n",
    "# Number of pixels\n",
    "n_original = int(area(final_snake_original))\n",
    "\n",
    "# Hyperparameters :\n",
    "print(f\"Hyperparamters : \")\n",
    "print(f\"    Initial snake center : {center}.\")\n",
    "print(f\"    Initial snake radius : {radius}.\")\n",
    "print(f\"    Active contour beta value : {beta_val}.\")\n",
    "print(f\"    Active contour w line value : {line_val}.\")\n",
    "print(f\"    Active contour w edge value : {edge_val}.\")\n",
    "\n",
    "# Results\n",
    "print(f\"Results : \")\n",
    "print(f\"    Size of the brain : {n_original} px in the {height}x{width} image.\")\n",
    "print(f\"    Percentage of area occupied by the brain in the image : {n_original*100/(width*height):.2f}%.\")\n",
    "\n",
    "# Plots\n",
    "n_lin = 1\n",
    "n_col = 2\n",
    "fig, ax = plt.subplots(n_lin, n_col, figsize=(n_col*size, n_lin*size))\n",
    "\n",
    "ax[0].imshow(original_img, cmap = 'gray')\n",
    "ax[0].plot(initial_snake[:, 1], initial_snake[:, 0], '--r', lw=3)\n",
    "ax[0].set_title(\"$I_1$ : Initial snake\")\n",
    "\n",
    "ax[1].imshow(original_img, cmap = 'gray')\n",
    "ax[1].plot(final_snake_original[:, 1], final_snake_original[:, 0], '-b', lw=3)\n",
    "ax[1].set_title(\"$I_2$ : Final snake\")\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.axis(\"off\")\n",
    "\n",
    "#End of cell\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result indicates that the surface of the brain is of 19259 px, which corresponds to 29.39% of the image size, as can be seen just above. \n",
    "The active contour may not be the best choice in this situation, as we are trying to get the grey zone out of the other different grey zone; on $I_2$ we can see that the snake doesn't stick as closely to the edge of the brain surface as the previous methods.\n",
    "We also have a lot of holes that we want to detect. That could be done with multiple active contour detections just for the holes. \n",
    "\n",
    "<br>\n",
    "\n",
    "This method requires a few meta parameters :\n",
    "- The initial snake position; the closer it is to the final snake, the better.\n",
    "- Beta, the smoothness of the line. We don't want to be too smooth as the brain has lots of folds.\n",
    "- `w_line`, the attraction to brightness. Here we want to keep away from the brighter areas and try to stay in the dark zones between the brain and the skull.\n",
    "- `w_edge`, the attraction to the edges. We want to stick as much as possible to edges.\n",
    "\n",
    "Those meta parameters allow to miss very few parts of the brain, but include some that shouldn't be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Thresholding\n",
    "<!-- Add your implementation and discussion -->\n",
    "\n",
    "In order to compute the size of the brain using contour detection, we start from the original image, $I_1$, and compute the subsequent images :\n",
    "- $I_2$, by equalizing $I_1$'s histogram, the original image. We obtain an image with values more spread on the dynamic available.\n",
    "- $I_3$, by thresholding $I_2$, the histogram equilized version of the original image. Ideally, we want at that stage to have the brain as a single region, separate from the other regions on the image. Unfortunately, that's not the case, and on the images below, it is visible that the right ocular region is attached to the brain after thresholding. It doesn't matter, because we can get rid of it at the next step.\n",
    "- $I_4$, by eroding $I_3$, the thresholded image, with a 3 x 3 kernel presenting a circle of radius 1 (i.e., a cross). We iterate the erosion until the ocular region is cut from the brain, that is three times. We obtain an eroded thresholded image, where the brain is one region, separate from the rest.\n",
    "- $I_5$, by flooding $I_4$, where the brain was isolated, with a initial seed withing the brain area. The two next steps are bitwise operations similar to the method with contour detection.\n",
    "- $I_6$, by performing the \"NOT\" bitwise operation on $I_5$. \n",
    "- $I_7$, by performing the \"AND\" bitwise operation on $I_6$ and $I_4$. We obtain an eroded version of the brain mask. To restore the correct brain mask, $I_8$, we just need one last step.\n",
    "- $I_8$, by dilating $I_7$, the eroded brain mask. We obtain a mask of the brain surface (brain surface is white on black background). We use the same kernel as for the erosion, and the same number of iterations.\n",
    "\n",
    "From there, we just count how many pixels are white in $I_8$, the mask, to have the size of the brain in pixels. To verify the quality of the result, we also compute $I_9$, by superimposing $I_8$, the mask of the brain, on $I_1$, the original image. It allows us to assess that the brain surface is indeed correct with visual proof.\n",
    "\n",
    "<br>\n",
    "\n",
    "All the steps from the original image to the brain mask and the quality control image (from $I_1$ to $I_9$) are displayed below, along with the implementation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram equalization \n",
    "equalized_img = cv.equalizeHist(original_img)\n",
    "\n",
    "# Plain threshold \n",
    "threshold = 127\n",
    "_, thresholded_img = cv.threshold(src=equalized_img, thresh=threshold, maxval=255, type=cv.THRESH_BINARY)\n",
    "\n",
    "cv.imwrite(\"test.png\", thresholded_img)\n",
    "\n",
    "# Erosion to cut the right eye\n",
    "iterations_num = 3\n",
    "kernel = np.zeros((3,3), np.uint8)\n",
    "cv.circle(img=kernel, center=(1,1), radius=1, color=255, thickness=-1) \n",
    "eroded_thresholded_img = cv.erode(thresholded_img, kernel, iterations=iterations_num)\n",
    "\n",
    "# Flood-filling from pixel (150, 150)\n",
    "mask = np.zeros((height+2, width+2), np.uint8)\n",
    "flooded_img = eroded_thresholded_img.copy()\n",
    "seed = (150,150)\n",
    "cv.floodFill(flooded_img, mask, seed, 0);\n",
    "\n",
    "# Inversion of the flood filled image \n",
    "eroded_inverted_flooded_img = cv.bitwise_not(flooded_img)\n",
    "\n",
    "# Combination of the thresholded image with the inverted flood filled image using bitwise AND operation \n",
    "eroded_brain_mask = cv.bitwise_and(eroded_inverted_flooded_img, eroded_thresholded_img)\n",
    "\n",
    "# Dilation to grow back the missing bits\n",
    "brain_mask = cv.dilate(eroded_brain_mask, kernel, iterations=iterations_num)\n",
    "\n",
    "# Superimposition\n",
    "empty_mask = np.zeros((height, width), np.uint8)\n",
    "color_brain_mask = cv.merge(mv=(empty_mask, empty_mask, brain_mask))\n",
    "color_original_img = cv.cvtColor(original_img, code=cv.COLOR_GRAY2RGB)\n",
    "superimposed_img = cv.add(src1=color_brain_mask, src2=color_original_img)\n",
    "\n",
    "# Number of pixels\n",
    "n = np.sum(brain_mask == 255)\n",
    "\n",
    "# Hyperparameters :\n",
    "print(f\"Hyperparamters : \")\n",
    "print(f\"    Threshold value : {threshold}.\")\n",
    "print(f\"    Number of erosions / dilations : {iterations_num}.\")\n",
    "print(f\"    Seed at {seed}.\")\n",
    "\n",
    "# Results\n",
    "print(f\"Results : \")\n",
    "print(f\"    Size of the brain : {n} px in the {height}x{width} image.\")\n",
    "print(f\"    Percentage of area occupied by the brain in the image : {n*100/(width*height):.2f}%.\")\n",
    "\n",
    "# Plots\n",
    "n_lin = 3\n",
    "n_col = 3\n",
    "fig, ax = plt.subplots(n_lin, n_col, figsize=(n_col*size, n_lin*size))\n",
    "\n",
    "ax[0,0].imshow(original_img, cmap = 'gray')\n",
    "ax[0,0].set_title(\"$I_1$ : Original image\")\n",
    "\n",
    "ax[0,1].imshow(equalized_img, cmap = 'gray')\n",
    "ax[0,1].set_title(\"$I_2$ : Histogram equalized image\")\n",
    "\n",
    "ax[0,2].imshow(thresholded_img, cmap = 'gray')\n",
    "ax[0,2].set_title(\"$I_3$ : Thresholded image\")\n",
    "\n",
    "ax[1,0].imshow(eroded_thresholded_img, cmap = 'gray')\n",
    "ax[1,0].set_title(\"$I_4$ : Eroded thresholded image\")\n",
    "\n",
    "ax[1,1].imshow(flooded_img, cmap = 'gray')\n",
    "ax[1,1].set_title(\"$I_5$ : Flooded eroded thresholded \\nimage with 0 in brain\")\n",
    "\n",
    "ax[1,2].imshow(eroded_inverted_flooded_img, cmap = 'gray')\n",
    "ax[1,2].set_title(\"$I_6$ : Inverted eroded flooded brain\")\n",
    "\n",
    "ax[2,0].imshow(eroded_brain_mask, cmap = 'gray')\n",
    "ax[2,0].set_title(\"$I_7$ : Eroded mask of brain surface ($I_4$ & $I_6$)\")\n",
    "\n",
    "ax[2,1].imshow(brain_mask, cmap = 'gray')\n",
    "ax[2,1].set_title(\"$I_8$ : Mask of brain surface\")\n",
    "\n",
    "ax[2,2].imshow(superimposed_img, cmap = 'gray')\n",
    "ax[2,2].set_title(\"$I_9$ : Control image (mask on original image)\")\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.axis(\"off\")\n",
    "\n",
    "#End of cell\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result indicates that the surface of the brain is of 16570 px, which corresponds to 25.28% of the image size, as can be seen just above. $I_9$, the quality control image, also shows that the segmentation is good, and thus that the result can be trusted.\n",
    "\n",
    "<br>\n",
    "\n",
    "This method requires a few meta parameters :\n",
    "- The first is the threshold value for the thresholding. Too high, and not all the brain is one piece during this crucial part of the segmentation. Too low, and bit of other cranial structures are attached to the brain. Unfortunately, the \"too high\" value is lower than the \"too low\" value, so we have to choose between the brain in its entierety but with bits of occular region attached, and the brain in several parts. Since it's easier to get rid of the occular parts later, we chose a value at which the brain is in one piece. Initially, we tried the Otsu threshold, which maximize inter-class variance, and minimizes intra-class variance; but it's just not a good threshold for this application.\n",
    "- The erosion kernel is also quite important. If it's too big, then the risk is to detach parts of the brain. That's why it's a cross on a 3 x 3 matrix. The same kernel is later used for the dilation to restore back the brain region.\n",
    "- The number of iterations to the dilation is dictated by need : it's the minimum number of iterations needed to detach the right occular region from the brain. The brain region, when segmented, is dilated the same number of time, to restore back the correct zone.\n",
    "- The flood-fill necessitates an initial seed, to begin the the flood-filling from. In order to find the surface of the brain, that seed needs to be located somewhere within that area. Thus, it can take many values, as long as the coordinates are within the surface of the brain. Here, they were chosen by estimation with the naked eye (trial and error), and ($x$,$y$)=(150,150) is such a coordinate.\n",
    "\n",
    "<br>\n",
    "\n",
    "Initially, the histogram equalization showed that 0-padding wide of 26 px was added to the original image. Because this adds artificial pixels of value 0 to the image, we wondered how it affected the histogram equalization. Thus, we equalized on the whole original image, and on a ROI of the original image, to see the difference :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram equalization on the whole image\n",
    "equalized_img = cv.equalizeHist(original_img)\n",
    "\n",
    "# Histogram equalization with ROI\n",
    "d = 26\n",
    "equalized_roi = original_img.copy()\n",
    "equalized_roi[:,d:width-d] = cv.equalizeHist(original_img[:,d:width-d])\n",
    "\n",
    "# Difference \n",
    "print(f\"Results : \")\n",
    "print(f\"    Norm of error between with ROI and without : {cv.norm(equalized_img, equalized_roi)}\")\n",
    "\n",
    "# Histograms \n",
    "hist_original, bins_original = np.histogram(a = original_img , bins = 256, range=[0,256])\n",
    "hist_equa_img, bins_equa_img = np.histogram(a = equalized_img, bins = 256, range=[0,256])\n",
    "hist_equa_roi, bins_equa_roi = np.histogram(a = equalized_roi, bins = 256, range=[0,256])\n",
    "\n",
    "# Normalized cumulative distribution functions\n",
    "cdf_original = hist_original.cumsum() \n",
    "cdf_equa_img = hist_equa_img.cumsum() \n",
    "cdf_equa_roi = hist_equa_roi.cumsum() \n",
    "\n",
    "cdf_original = cdf_original * hist_original.max() / cdf_original.max()\n",
    "cdf_equa_img = cdf_equa_img * hist_equa_img.max() / cdf_equa_img.max()\n",
    "cdf_equa_roi = cdf_equa_roi * hist_equa_roi.max() / cdf_equa_roi.max()\n",
    "\n",
    "# Plots\n",
    "n_lin = 2\n",
    "n_col = 3\n",
    "fig, ax = plt.subplots(n_lin, n_col, figsize=(n_col*size, n_lin*size))\n",
    "\n",
    "ax[0,0].imshow(original_img, cmap = 'gray')\n",
    "ax[0,0].set_title(\"Original image\")\n",
    "\n",
    "ax[0,1].imshow(equalized_img, cmap = 'gray')\n",
    "ax[0,1].set_title(\"Equalized without ROI\")\n",
    "\n",
    "ax[0,2].imshow(equalized_roi, cmap = 'gray')\n",
    "ax[0,2].set_title(\"Equalized without ROI\")\n",
    "\n",
    "ax[1,0].plot(cdf_original, color = 'b')\n",
    "ax[1,0].hist(original_img.flatten(),256,[0,256], color = 'r')\n",
    "ax[1,0].set_title(\"Histogram of original image with CDF\")\n",
    "ax[1,0].set_xlim([0,256])\n",
    "\n",
    "ax[1,1].plot(cdf_equa_img, color = 'b')\n",
    "ax[1,1].hist(equalized_img.flatten(),256,[0,256], color = 'r')\n",
    "ax[1,1].set_title(\"Histogram of equalized image without ROI, with CDF\")\n",
    "ax[1,1].set_xlim([0,256])\n",
    "\n",
    "ax[1,2].plot(cdf_equa_roi, color = 'b')\n",
    "ax[1,2].hist(equalized_roi.flatten(),256,[0,256], color = 'r')\n",
    "ax[1,2].set_title(\"Histogram of equalized image with ROI, image with CDF\")\n",
    "ax[1,2].set_xlim([0,256])\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.axis(\"off\")\n",
    "\n",
    "#End of cell\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the histogram of the original image is skewed on the left, and because of the inherent discrete nature of it, it doesn't impact the equalization, and they both give exactly the same result (the norm of the error between the two equlized histogram is 0). Had the values of the image without the padding been skewed on the right instead, it would have led to very distinct histograms.\n",
    "\n",
    "<br>\n",
    "\n",
    "Another trial (and error) experimented was an adaptive threshold. Adaptive thresholds work great on pictures which cast shadows, because the threshold is determined automatically from values from neighboring pixels, and maybe that thresholding method would segment better the brain from the skull. The downside is that it requires a new meta-parameter, namely how we determine which pixels are considered neighboring pixels. Here are the result of those investigations, along with the result from plain Otsu thresholding, to illustrate why we didn't keep those implementations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram equalization on the whole image\n",
    "equalized_img = cv.equalizeHist(original_img)\n",
    "\n",
    "# Otsu thresholding\n",
    "_, otsu_img = cv.threshold(src=equalized_img, thresh=0, maxval=255, type=(cv.THRESH_BINARY | cv.THRESH_OTSU))\n",
    "\n",
    "# Adaptive thresholding\n",
    "maxVal=255\n",
    "constant = 2\n",
    "\n",
    "blocksize = 51\n",
    "img_1 = cv.adaptiveThreshold(src=equalized_img, maxValue=maxVal, adaptiveMethod=cv.ADAPTIVE_THRESH_MEAN_C, thresholdType=cv.THRESH_BINARY, blockSize=11, C=constant)\n",
    "img_2 = cv.adaptiveThreshold(src=equalized_img, maxValue=maxVal, adaptiveMethod=cv.ADAPTIVE_THRESH_GAUSSIAN_C, thresholdType=cv.THRESH_BINARY, blockSize=11, C=constant)\n",
    "\n",
    "blocksize = 151\n",
    "img_3 = cv.adaptiveThreshold(src=equalized_img, maxValue=maxVal, adaptiveMethod=cv.ADAPTIVE_THRESH_MEAN_C, thresholdType=cv.THRESH_BINARY, blockSize=11, C=constant)\n",
    "img_4 = cv.adaptiveThreshold(src=equalized_img, maxValue=maxVal, adaptiveMethod=cv.ADAPTIVE_THRESH_GAUSSIAN_C, thresholdType=cv.THRESH_BINARY, blockSize=11, C=constant)\n",
    "\n",
    "blocksize = 251\n",
    "img_5 = cv.adaptiveThreshold(src=equalized_img, maxValue=maxVal, adaptiveMethod=cv.ADAPTIVE_THRESH_MEAN_C, thresholdType=cv.THRESH_BINARY, blockSize=11, C=constant)\n",
    "img_6 = cv.adaptiveThreshold(src=equalized_img, maxValue=maxVal, adaptiveMethod=cv.ADAPTIVE_THRESH_GAUSSIAN_C, thresholdType=cv.THRESH_BINARY, blockSize=11, C=constant)\n",
    "\n",
    "# Plots\n",
    "n_lin = 4\n",
    "n_col = 2\n",
    "fig, ax = plt.subplots(n_lin, n_col, figsize=(n_col*size, n_lin*size))\n",
    "\n",
    "ax[0,0].imshow(otsu_img, cmap = 'gray')\n",
    "ax[0,0].set_title(\"Otsu threshold\")\n",
    "\n",
    "# ax[0,1].imshow(equalized_img, cmap = 'gray')\n",
    "# ax[0,1].set_title(\"Equalized without ROI\")\n",
    "\n",
    "ax[1,0].imshow(img_1, cmap = 'gray')\n",
    "ax[1,0].set_title(\"Adaptive mean theshold, blocksize of 51\")\n",
    "\n",
    "ax[1,1].imshow(img_2, cmap = 'gray')\n",
    "ax[1,1].set_title(\"Adaptive gaussian theshold, blocksize of 51\")\n",
    "\n",
    "ax[2,0].imshow(img_3, cmap = 'gray')\n",
    "ax[2,0].set_title(\"Adaptive mean theshold, blocksize of 151\")\n",
    "\n",
    "ax[2,1].imshow(img_4, cmap = 'gray')\n",
    "ax[2,1].set_title(\"Adaptive gaussian theshold, blocksize of 151\")\n",
    "\n",
    "ax[3,0].imshow(img_5, cmap = 'gray')\n",
    "ax[3,0].set_title(\"Adaptive mean theshold, blocksize of 251\")\n",
    "\n",
    "ax[3,1].imshow(img_6, cmap = 'gray')\n",
    "ax[3,1].set_title(\"Adaptive gaussian theshold, blocksize of 251\")\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.axis(\"off\")\n",
    "\n",
    "#End of cell\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of these threshold are as nice as the plain, hand-tuned threshold used (considering our application)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Shape/color segmentation\n",
    "\n",
    "You will find hereafter three pictures taken under three different illuminations, containing some shapes with different colors. We ask you to create a routine to:\n",
    "\n",
    "1. Count the number of shapes of each color.\n",
    "2. Compute the total area (in pixels) of each color.\n",
    "\n",
    "Please note that one specific challenge is to be robust to illumination changes. Therefore some kind of intensity normalization should probably be used.\n",
    "\n",
    "**Note:** the routine(s) that you will write for this exercise will be useful for the final project as well, so pay special attention to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "img_names = [\"arena-shapes-01\", \"arena-shapes-02\", \"arena-shapes-03\"]\n",
    "filenames = [os.path.join(data_path, name) + \".png\" for name in img_names]\n",
    "img_files = skimage.io.imread_collection(filenames)\n",
    "imgs = skimage.io.concatenate_images(img_files)\n",
    "\n",
    "# Print information\n",
    "img_num = imgs.shape[0]\n",
    "img_size = (imgs.shape[1],imgs.shape[2])\n",
    "channel_num = imgs.shape[-1]\n",
    "print(f\"Number of images: {img_num}\")\n",
    "print(f\"Image size : {img_size[0]}x{img_size[1]}\")\n",
    "print(f\"Number of color channels : {channel_num}\")\n",
    "\n",
    "# Plots\n",
    "n_lin = 1\n",
    "n_col = 3\n",
    "size = 6\n",
    "fig, ax = plt.subplots(n_lin, n_col, figsize=(n_col*size, n_lin*size))\n",
    "\n",
    "for a, img, name in zip(ax.flatten(), imgs, img_names):\n",
    "    a.imshow(img)\n",
    "    a.axis(\"off\")\n",
    "    a.set_title(name)\n",
    "\n",
    "# End of cell\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the RGB and HSV values from the three images for the blue, purple, and background, we obtain the following results.\n",
    "\n",
    "For RGB values :\n",
    "\n",
    "|            | arena-shapes-01 | arena-shapes-02 | arena-shapes-03 |\n",
    "| ---------- | --------------- | --------------- | --------------- |\n",
    "| Blue       | 110 , 130 , 227 | 110 , 130 , 227 | 032 , 041 , 088 |\n",
    "| Black      | 032 , 032 , 048 | 034 , 033 , 049 | 021 , 021 , 031 |\n",
    "| Background | 193 , 181 , 182 | 193 , 182 , 183 | 135 , 123 , 123 |\n",
    "\n",
    "For HSV values :\n",
    "\n",
    "|            | arena-shapes-01     | arena-shapes-02     | arena-shapes-03     |\n",
    "| ---------- | ------------------- | ------------------- | ------------------- |\n",
    "| Blue       | 229.0 , 53.3 , 88.9 | 232.8 , 51.7 , 89.0 | 230.4 , 63.8 , 34.5 |\n",
    "| Black      | 242.1 , 28.4 , 16.8 | 250.3 , 37.9 , 39.1 | 242.2 , 34.8 , 12.5 |\n",
    "| Background | 339.5 , 07.2 , 75.4 | 353.6 , 06.5 , 75.3 | 337.6 , 09.4 , 52.6 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterColorFromImg(image, colorRange):\n",
    "    grayscale_img = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    equalized_img = cv.equalizeHist(grayscale_img)\n",
    "    filtered_img = cv.inRange(equalized_img,colorRange[0],colorRange[1])\n",
    "    kernel = np.zeros((5,5), np.uint8)\n",
    "    cv.circle(img=kernel, center=(2,2), radius=2, color=255, thickness=-1)\n",
    "    closed_img = cv.morphologyEx(filtered_img, cv.MORPH_CLOSE, kernel, iterations=1)\n",
    "    mask = cv.morphologyEx(closed_img, cv.MORPH_OPEN, kernel, iterations=1)\n",
    "\n",
    "    return mask, grayscale_img, equalized_img, filtered_img, closed_img\n",
    "\n",
    "# threhold ranges\n",
    "blueRange = (4,8)\n",
    "blackRange = (0,3)\n",
    "\n",
    "#plot parameters\n",
    "n_lin = 6\n",
    "n_col = 2\n",
    "size = 6\n",
    "fig, ax = plt.subplots(n_lin, n_col, figsize=(n_col*size, n_lin*size))\n",
    "\n",
    "#definitions\n",
    "black = 0\n",
    "blue  = 1\n",
    "labels = [\"Arena shapes\", \"Grayscale\", \"Histogram equalization\", \"Black threshold\", \"Morph operation\", \"Blue threshold\"]\n",
    "\n",
    "# loop to print all different images\n",
    "for col in [black,blue]:\n",
    "    if col == black:\n",
    "        a,b,c,d,e = filterColorFromImg(img,blackRange)\n",
    "    else:\n",
    "        a,b,c,d,e = filterColorFromImg(img,blueRange)\n",
    "    for idx,im in enumerate([imgs[0],b,c,d,e,a]):\n",
    "        ax[idx,col].imshow(im, cmap=\"gray\")\n",
    "        ax[idx,col].set_title(\"$I_{\" + str(col+1) + str(idx+1) + \"}$ : \" + labels[idx] + \" 0\" + str(col+1))\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Number of shapes of each color\n",
    "Add your implementation and discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing, results and plot\n",
    "n_lin = 3\n",
    "n_col = 3\n",
    "size = 6\n",
    "fig, ax = plt.subplots(n_lin, n_col, figsize=(n_col*size, n_lin*size))\n",
    "print(f\"Results : \")\n",
    "for img, name, i in zip(imgs, img_names, range(img_num)):\n",
    "    black_img,_,_,_,_ = filterColorFromImg(img,blackRange)\n",
    "    blue_img,_,_,_,_ = filterColorFromImg(img,blueRange)\n",
    "    black_shape_num,_ = cv.connectedComponents(image=black_img)\n",
    "    blue_shape_num,_ = cv.connectedComponents(image=blue_img)\n",
    "\n",
    "    print(f\"    Number of black shapes in {name} : {black_shape_num-1}\")\n",
    "    print(f\"    Number of black shapes in {name} : {blue_shape_num-1}\")\n",
    "    print(f\"\")\n",
    "    \n",
    "    ax[0,i].imshow(img, cmap=\"gray\")\n",
    "    ax[0,i].set_title(name)\n",
    "\n",
    "    ax[1,i].imshow(black_img, cmap=\"gray\")\n",
    "    ax[1,i].set_title(\"Black filter on \" + name)\n",
    "\n",
    "    ax[2,i].imshow(blue_img, cmap=\"gray\")\n",
    "    ax[2,i].set_title(\"Blue filter on \" + name)\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.axis(\"off\")\n",
    "    \n",
    "# End of cell\n",
    "print(f\"End of cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Total area (in pixels) of each color\n",
    "Add your implementation and discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Results : \")\n",
    "for img, name, i in zip(imgs, img_names, range(img_num)):\n",
    "    # Extraction\n",
    "    black_shapes,_,_,_,_ = filterColorFromImg(img,blackRange)\n",
    "    blue_shapes,_,_,_,_ = filterColorFromImg(img,blueRange)\n",
    "    black_pixel_num = np.sum(black_shapes == 255)\n",
    "    blue_pixel_num = np.sum(blue_shapes == 255)\n",
    "    \n",
    "    # Results\n",
    "    print(f\"    There are {black_pixel_num} black px and {blue_pixel_num} blue px in {name}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
