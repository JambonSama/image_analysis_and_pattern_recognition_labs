{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR 2020:][iapr2020] Lab 1 â€’  Image segmentation\n",
    "\n",
    "**Authors:** Claire Meyer, Nicolas Furrer, Philipp Schuler  \n",
    "**Due date:** 26.03.2020\n",
    "\n",
    "[iapr2018]: https://github.com/LTS5/iapr-2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract relevant data\n",
    "We first need to extract the `lab-01-data.tar.gz` archive.\n",
    "To this end, we use the [tarfile] module from the Python standard library.\n",
    "\n",
    "[tarfile]: https://docs.python.org/3.6/library/tarfile.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "data_base_path = os.path.join(os.pardir, \"data\")\n",
    "data_folder = \"lab-01-data\"\n",
    "#tar_path = os.path.join(data_base_path, data_folder + '.tar.gz')\n",
    "#with tarfile.open(tar_path, mode='r:gz') as tar:\n",
    "#    tar.extractall(path=data_base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Brain segmentation\n",
    "\n",
    "Your goal: compute the size of the brain (in pixels) in a 2D image of a human head taken by Magnetic Resonance Imaging (MRI).\n",
    "* Try as many methods as you can, the more the better.\n",
    "* At least region growing and contour detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Brain image visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# Load image with OpenCV\n",
    "data_path = os.path.join(data_base_path, data_folder)\n",
    "original_img = cv.imread(os.path.join(data_path, \"brain-slice40.tiff\"),0)\n",
    "height, width = original_img.shape[:2]\n",
    "\n",
    "# Plot image\n",
    "n_lin = 1\n",
    "n_col = 1\n",
    "size = 6\n",
    "fig, ax = plt.subplots(n_lin, n_col, figsize=(n_col*size, n_lin*size))\n",
    "ax.imshow(original_img, cmap=\"gray\")\n",
    "ax.set_title(\"MRI brain image ({} px, {} px)\".format(height,width))\n",
    "ax.axis(\"off\")\n",
    "\n",
    "#End of cell\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Region growing\n",
    "Add your implementation and discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def region_growing(image, seed, low_threshold, high_threshold):\n",
    "#     mask = np.zeros((height+2,width+2),np.uint8)\n",
    "#     cv.floodFill(image, mask, seed, 255,low_threshold, high_threshold)\n",
    "#     return image, mask\n",
    "\n",
    "# brain_im_c = original_img.copy()\n",
    "# seed = (150,150)\n",
    "# image, mask = region_growing(brain_im_c, seed, 6, 6)\n",
    "# mask_h, mask_w = mask.shape\n",
    "# count = 0\n",
    "# for x in range(mask_w):\n",
    "#     for y in range(mask_h):\n",
    "#         if mask[x,y]==1:\n",
    "#             count = count + 1\n",
    "\n",
    "# #Plot\n",
    "# print(\"Seed : \" , seed)\n",
    "# print(\"Brain size : \", count, \" Pixels\")\n",
    "# ax = plt.subplot(1,3,1)\n",
    "# ax.set_title(\"Base image\")\n",
    "# ax.imshow(original_img, cmap='gray')\n",
    "# ax.axis('off')\n",
    "# ax = plt.subplot(1,3,2)\n",
    "# ax.set_title(\"Brain detection\")\n",
    "# ax.imshow(image, cmap='gray')\n",
    "# ax.axis('off')\n",
    "# ax = plt.subplot(1,3,3,)\n",
    "# ax.set_title(\"Brain mask\")\n",
    "# ax.imshow(mask, cmap ='gray')\n",
    "# ax.axis('off')\n",
    "\n",
    "########################################\n",
    "# IMPORTANT : pourquoi les modifications\n",
    "########################################\n",
    "# Le mask qui sort de FloodFill a une taille de (w+2)x(h+2), et la bande qui est ajoutee autour de l image d'origine est blanche. \n",
    "# Du coup dans ton compteur, non seulement tu comptes pas sur tout le masque (vu que tu compte de 0 a w, et de 0 a h, au lieu de 0 a w+2 et de 0 a h+2), \n",
    "# mais en plus tu prends une moitie de bande blanche dans le compte, donc le resultat est faux.\n",
    "# J ai simplifie + corrige le code.\n",
    "\n",
    "\n",
    "# Region growing from pixel (150,150)\n",
    "grown_img = original_img.copy()\n",
    "seed = (150,150)\n",
    "t1 = 6\n",
    "t2 = 24\n",
    "mask = np.zeros((height+2,width+2), np.uint8)\n",
    "cv.floodFill(image=grown_img, mask=mask, seedPoint=seed, newVal=255, loDiff=t1, upDiff=t2)\n",
    "\n",
    "# Getting the mask back\n",
    "brain_mask = mask[1:width+1,1:height+1].copy()*255\n",
    "cv.imwrite(filename=\"test.png\", img=brain_mask)\n",
    "\n",
    "# Superimposition\n",
    "empty_mask = np.zeros((height, width), np.uint8)\n",
    "color_brain_mask = cv.merge(mv=(empty_mask, empty_mask, brain_mask))\n",
    "color_original_img = cv.cvtColor(original_img, code=cv.COLOR_GRAY2RGB)\n",
    "superimposed_img = cv.add(src1=color_brain_mask, src2=color_original_img)\n",
    "\n",
    "# Number of pixels\n",
    "n = np.sum(brain_mask == 255)\n",
    "\n",
    "# Hyperparameters :\n",
    "print(f\"Hyperparamters : \")\n",
    "print(f\"    Seed at {seed}.\")\n",
    "print(f\"    Max lower difference : {t1}.\")\n",
    "print(f\"    Max upper difference : {t2}.\")\n",
    "\n",
    "# Results\n",
    "print(f\"Results : \")\n",
    "print(f\"    Size of the brain : {n} px in the {height}x{width} image.\")\n",
    "print(f\"    Percentage of area occupied by the brain in the image : {n*100/(width*height):.2f}%.\")\n",
    "\n",
    "# Plots\n",
    "n_lin = 2\n",
    "n_col = 2\n",
    "fig, ax = plt.subplots(n_lin, n_col, figsize=(n_col*size, n_lin*size))\n",
    "\n",
    "ax[0,0].imshow(original_img, cmap = 'gray')\n",
    "ax[0,0].set_title(\"$I_1$ : Original image\")\n",
    "\n",
    "ax[0,1].imshow(grown_img, cmap = 'gray')\n",
    "ax[0,1].set_title(\"$I_2$ : Region growing result\")\n",
    "\n",
    "ax[1,0].imshow(brain_mask, cmap = 'gray')\n",
    "ax[1,0].set_title(\"$I_3$ : Mask of brain surface\")\n",
    "\n",
    "ax[1,1].imshow(superimposed_img, cmap = 'gray')\n",
    "ax[1,1].set_title(\"$I_4$ : Control image (mask on original image)\")\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.axis(\"off\")\n",
    "\n",
    "#End of cell\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "Cest la la discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Contour detection\n",
    "<!-- Add your implementation and discussion -->\n",
    "\n",
    "In order to compute the size of the brain using contour detection, we start from the original image, $I_1$, and compute the subsequent images :\n",
    "- $I_2$, by applying the Canny algorithm on $I_1$, the original image. We obtain the contours of the original image. But those contours are not closed, they are just edges from the original image. To determine a region (here, the brain), we need the contour around that region closed (the other contours don't matter).\n",
    "- $I_3$, by dilating $I_2$, the contours. We obtained closed contours, because the dilation of the contours make them grow. Thus, the area containing the brain is determined by a closed contour.\n",
    "- $I_4$, by flood-filling $I_3$, the closed contours, with a initial seed in the brain. We obtain a compound black image, with the closed dilated contours and the brain surface in white. Indeed, flood-filling fills a zone on the basis of a continuous color (or here, lack thereof). Because we fill from the inside of the brain (black), and the brain is closed by closed contours (white); after flood-filling, the brain is white.\n",
    "- $I_5$, by performing the \"NOT\" bitwise operation on $I_4$. We obtain a compound white image, with the closed dilated contours and the brain surface in black. The operations to obtain $I_5$ and $I_6$ are just logical operations on the images, to obtain what we want.\n",
    "- $I_6$, by performing the \"OR\" bitwise operation on $I_3$ and $I_5$. Since $I_3$ contains the closed dilated contours, and $I_5$ anything but the contours and the brain surface, we obtain a white image with the brain surface in black. That brain surface is eroded compared to the real size, because of the previous dilation (of the edges of the brain).\n",
    "- $I_7$, by eroding $I_6$. We obtain a white image with the brain in black, but this time the correct surface. We need this erosion because we had to dilate $I_2$, to close the contours. This dilation \"ate away\" at the brain, so now we need to \"grow it back up\". This is done by erosion because the brain is in black, not in white. \n",
    "- $I_8$, by performing the \"NOT\" bitwise operation on $I_7$. We obtain a mask of the brain surface (brain surface is white on black background).\n",
    "\n",
    "From there, we just count how many pixels are white in $I_8$, the mask, to have the size of the brain in pixels. To verify the quality of the result, we also compute $I_9$, by superimposing $I_8$, the mask of the brain, on $I_1$, the original image. It allows us to assess that the brain surface is indeed correct with visual proof.\n",
    "\n",
    "<br>\n",
    "\n",
    "All the steps from the original image to the brain mask and the quality control image (from $I_1$ to $I_9$) are displayed below, along with the implementation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny detection \n",
    "t1 = 85\n",
    "t2 = 200\n",
    "edges_img = cv.Canny(image=original_img, threshold1=t1, threshold2=t2, apertureSize=3)\n",
    "\n",
    "# Dilation of contours\n",
    "kernel = np.zeros((3,3), np.uint8)\n",
    "cv.circle(img=kernel, center=(1,1), radius=1, color=255, thickness=-1) \n",
    "dilated_edges_img = cv.dilate(edges_img, kernel, iterations=1)\n",
    "\n",
    "# Flood-filling from pixel (150, 150)\n",
    "mask = np.zeros((height+2, width+2), np.uint8)\n",
    "flooded_img = dilated_edges_img.copy()\n",
    "seed = (150,150)\n",
    "cv.floodFill(flooded_img, mask, seed, 255);\n",
    "\n",
    "# Inversion of the flood filled image \n",
    "inverted_flooded_img = cv.bitwise_not(flooded_img)\n",
    "\n",
    "# Combination of the thresholded image with the inverted flood filled image using bitwise OR operation \n",
    "dilated_segmented_img = cv.bitwise_or(dilated_edges_img, inverted_flooded_img)\n",
    "segmented_img = cv.erode(dilated_segmented_img, kernel, iterations=1)\n",
    "\n",
    "# Brain mask\n",
    "brain_mask = cv.bitwise_not(segmented_img)\n",
    "\n",
    "# Superimposition\n",
    "empty_mask = np.zeros((height, width), np.uint8)\n",
    "color_brain_mask = cv.merge(mv=(empty_mask, empty_mask, brain_mask))\n",
    "color_original_img = cv.cvtColor(original_img, code=cv.COLOR_GRAY2RGB)\n",
    "superimposed_img = cv.add(src1=color_brain_mask, src2=color_original_img)\n",
    "\n",
    "# Number of pixels\n",
    "n = np.sum(brain_mask == 255)\n",
    "\n",
    "# Hyperparameters :\n",
    "print(f\"Hyperparamters : \")\n",
    "print(f\"    Seed at {seed}.\")\n",
    "print(f\"    Low Canny threshold : {t1}.\")\n",
    "print(f\"    High Canny threshold : {t2}.\")\n",
    "\n",
    "# Results\n",
    "print(f\"Results : \")\n",
    "print(f\"    Size of the brain : {n} px in the {height}x{width} image.\")\n",
    "print(f\"    Percentage of area occupied by the brain in the image : {n*100/(width*height):.2f}%.\")\n",
    "\n",
    "# Plots\n",
    "n_lin = 3\n",
    "n_col = 3\n",
    "fig, ax = plt.subplots(n_lin, n_col, figsize=(n_col*size, n_lin*size))\n",
    "\n",
    "ax[0,0].imshow(original_img, cmap = 'gray')\n",
    "ax[0,0].set_title(\"$I_1$ : Original image\")\n",
    "\n",
    "ax[0,1].imshow(edges_img, cmap = 'gray')\n",
    "ax[0,1].set_title(\"$I_2$ : Contours of original image\")\n",
    "\n",
    "ax[0,2].imshow(dilated_edges_img, cmap = 'gray')\n",
    "ax[0,2].set_title(\"$I_3$ : Closed, dilated contours\")\n",
    "\n",
    "ax[1,0].imshow(flooded_img, cmap = 'gray')\n",
    "ax[1,0].set_title(\"$I_4$ : Closed, dilated contours and brain surface in white\")\n",
    "\n",
    "ax[1,1].imshow(inverted_flooded_img, cmap = 'gray')\n",
    "ax[1,1].set_title(\"$I_5$ : Closed, dilated contours and brain surface in black\")\n",
    "\n",
    "ax[1,2].imshow(dilated_segmented_img, cmap = 'gray')\n",
    "ax[1,2].set_title(\"$I_6$ : Mask of everything but brain \\n(the brain is a little bit eroded away\\nbecause of the dilation at the third step)\")\n",
    "\n",
    "ax[2,0].imshow(segmented_img, cmap = 'gray')\n",
    "ax[2,0].set_title(\"$I_7$ : Mask of brain surface\")\n",
    "\n",
    "ax[2,1].imshow(brain_mask, cmap = 'gray')\n",
    "ax[2,1].set_title(\"$I_8$ : Mask of brain surface\")\n",
    "\n",
    "ax[2,2].imshow(superimposed_img, cmap = 'gray')\n",
    "ax[2,2].set_title(\"$I_9$ : Control image (mask on original image)\")\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.axis(\"off\")\n",
    "\n",
    "#End of cell\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result indicates that the surface of the brain is of 15742 px, which corresponds to 24.02% of the image size, as can be seen just above. $I_9$, the quality control image, also shows that the segmentation is good, and thus that the result can be trusted.\n",
    "\n",
    "<br>\n",
    "\n",
    "This method requires a few meta parameters :\n",
    "- $t_1$ and $t_2$, the thresholds for the Canny edges detector. Those two threshold mark the strong and weak edges : anything above the highest threshold is a strong edge, anything below the lowest threshold is deleted, and the rest is a weak edge, whose validity is determined by its link, or lack thereof, to a strong edge. Those values are determined empirically, and influence drastically the result of the edge detection. Here, we chose $t_1$=85 and $t_2$=200.\n",
    "- The dilation kernel $K$ is also quite important. If too small, the dilation doesn't close the edges. If too big, some edges that should remain separate become fused. Here, the kernel is a circle of radius 1, which is equivalent to a cross on a 3x3 matrix. To ensure some degree of consistency, the same kernel is used for the subsequent erosion.\n",
    "- Similarly, the dilation iteration number, if too high, can fuse edges that should remain separate. Here, we only iterated the dilation once; and thus we only eroded once as well, for consistency.\n",
    "- The flood-fill necessitates an initial seed, to begin the the flood-filling from. In order to find the surface of the brain, that seed needs to be located somewhere within that area. Thus, it can take many values, as long as the coordinates are within the surface of the brain. Here, they were chosen by estimation with the naked eye (trial and error), and ($x$,$y$)=(150,150) is such a coordinate.\n",
    "\n",
    "<br>\n",
    "\n",
    "Initially, we tried an histogram equalization on the original image, to see if we could determine the edges more acurately that way. It proved to be severely unhelpful, to the point of being deleterious to the result. When looking at the result of an histogram equalization, we can easily see why. Indeed a lot of noise is enhanced by the equalization, to the point where there are way too many false positive when trying to detect the edges with the Canny algorithm. Below are shown the original image, the histogram equalization of that original image, and the edges detected with the Canny algorithm from that equalized image :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram equalization \n",
    "equalized_img = cv.equalizeHist(original_img)\n",
    "\n",
    "# Canny detection \n",
    "t1 = 240\n",
    "t2 = 245\n",
    "edges_img_2 = cv.Canny(image=equalized_img,threshold1=t1,threshold2=t2,apertureSize=3)\n",
    "\n",
    "# Plots\n",
    "n_lin = 1\n",
    "n_col = 3\n",
    "fig, ax = plt.subplots(n_lin, n_col, figsize=(n_col*size, n_lin*size))\n",
    "\n",
    "ax[0].imshow(original_img, cmap = 'gray')\n",
    "ax[0].set_title(\"Original image\")\n",
    "\n",
    "ax[1].imshow(equalized_img, cmap = 'gray')\n",
    "ax[1].set_title(\"Equalized original image\")\n",
    "\n",
    "ax[2].imshow(edges_img_2, cmap = 'gray')\n",
    "ax[2].set_title(\"Contours detected on equalized image\")\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.axis(\"off\")\n",
    "\n",
    "#End of cell\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to try and detect only the strongest edges, the Canny thresholds are set very high, to keep only the strongest of edges, but there are still too many false positive : the equalization broke the edges on the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Additional method(s)\n",
    "Add your implementation and discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Active Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import gaussian\n",
    "from skimage.segmentation import active_contour\n",
    "\n",
    "def area(contour):\n",
    "    area = 0\n",
    "    x0,y0 = contour[0]\n",
    "    for [x1,y1] in contour[1:]:\n",
    "        dx = x1-x0\n",
    "        dy = y1-y0\n",
    "        area += 0.5*(y0*dx - x0*dy)\n",
    "        x0 = x1\n",
    "        y0 = y1\n",
    "    return area\n",
    "\n",
    "# Initialisation of the snake as a circle centered around the brain\n",
    "center = (147, 125)\n",
    "radius = 75\n",
    "samples = np.linspace(0, 2*np.pi, 400)\n",
    "sine = center[0] + radius*np.sin(samples)\n",
    "cosine = center[1] + radius*np.cos(samples)\n",
    "initial_snake = np.array([sine, cosine]).T\n",
    "\n",
    "# Gaussian blur\n",
    "blurred_img = gaussian(original_img, 1)\n",
    "\n",
    "# Active contour detection \n",
    "# beta : smoothness of the line, we don't want to be too smooth as the brain has lots of folds\n",
    "# w_line : attraction to brightness. Here we want to keep away from the brighter areas and try to stay in the dark zones between the brain and the skull\n",
    "# w_edge : attraction to the edges. We want to stick as much as possible to edges\n",
    "final_snake_original = active_contour(original_img, initial_snake, beta=4, w_line=-5, w_edge=10, coordinates='rc')\n",
    "final_snake_blurred = active_contour(blurred_img, initial_snake, beta = 4, w_line=-5, w_edge=10, coordinates='rc')\n",
    "\n",
    "# Number of pixels\n",
    "n_original = int(area(final_snake_original))\n",
    "n_blurred = int(area(final_snake_blurred));\n",
    "\n",
    "# Results\n",
    "print(f\"Results original: \")\n",
    "print(f\"    Size of the brain : {n_original} px in the {height}x{width} image.\")\n",
    "print(f\"    Percentage of area occupied by the brain in the image : {n_original*100/(width*height):.2f}%.\")\n",
    "print(f\"Results blurred: \")\n",
    "print(f\"    Size of the brain : {n_blurred} px in the {height}x{width} image.\")\n",
    "print(f\"    Percentage of area occupied by the brain in the image : {n_blurred*100/(width*height):.2f}%.\")\n",
    "\n",
    "# Plots\n",
    "n_lin = 2\n",
    "n_col = 2\n",
    "fig, ax = plt.subplots(n_lin, n_col, figsize=(n_col*size, n_lin*size))\n",
    "\n",
    "ax[0,0].imshow(original_img, cmap = 'gray')\n",
    "ax[0,0].plot(initial_snake[:, 1], initial_snake[:, 0], '--r', lw=3)\n",
    "ax[0,0].set_title(\"$I_1$ : Initial snake\")\n",
    "\n",
    "ax[0,1].imshow(original_img, cmap = 'gray')\n",
    "ax[0,1].plot(final_snake_original[:, 1], final_snake_original[:, 0], '-b', lw=3)\n",
    "ax[0,1].set_title(\"$I_2$ : Final snake on original image\")\n",
    "\n",
    "ax[1,0].imshow(blurred_img, cmap = 'gray')\n",
    "ax[1,0].plot(initial_snake[:, 1], initial_snake[:, 0], '--r', lw=3)\n",
    "ax[1,0].set_title(\"$I_1$ : Blurred image\")\n",
    "\n",
    "ax[1,1].imshow(blurred_img, cmap = 'gray')\n",
    "ax[1,1].plot(final_snake_blurred[:, 1], final_snake_blurred[:, 0], '-b', lw=3)\n",
    "ax[1,1].set_title(\"$I_2$ : Final snake on blurred image\")\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.axis(\"off\")\n",
    "\n",
    "#End of cell\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Active contour discussion\n",
    "The active contour may not be the best choice in this situation, as we are trying to get the grey zone out of the other different grey zone. \n",
    "We also have a lot of holes that we want to detect. That could be done with multiple active contour detections just for the holes. \n",
    "The parameters choosen here, give a good segmentation of the brain with very little parts that are missed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Shape/color segmentation\n",
    "\n",
    "You will find hereafter three pictures taken under three different illuminations, containing some shapes with different colors. We ask you to create a routine to:\n",
    "\n",
    "1. Count the number of shapes of each color.\n",
    "2. Compute the total area (in pixels) of each color.\n",
    "\n",
    "Please note that one specific challenge is to be robust to illumination changes. Therefore some kind of intensity normalization should probably be used.\n",
    "\n",
    "**Note:** the routine(s) that you will write for this exercise will be useful for the final project as well, so pay special attention to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "im_names = ['arena-shapes-01', 'arena-shapes-02', 'arena-shapes-03']\n",
    "filenames = [os.path.join(data_path, name) + '.png' for name in im_names]\n",
    "ic = skimage.io.imread_collection(filenames)\n",
    "images = skimage.io.concatenate_images(ic)\n",
    "print('Number of images: ', images.shape[0])\n",
    "print('Image size: {}, {} '.format(images.shape[1], images.shape[2]))\n",
    "print('Number of color channels: ', images.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 12))\n",
    "for ax, im, nm in zip(axes.ravel(), images, im_names):\n",
    "    ax.imshow(im)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Number of shapes of each color\n",
    "Add your implementation and discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 12))\n",
    "for ax, im, nm in zip(axes.ravel(), images, im_names):\n",
    "    \n",
    "    im_hsv = cv.cvtColor(im, cv.COLOR_BGR2HSV)\n",
    "    #ax.imshow(im_hsv)\n",
    "    m = np.mean(im_hsv[:,:,2])\n",
    "    mean = 210-m\n",
    "    im_hsv[:,:,2] += np.uint8(mean)\n",
    "    \n",
    "    im_hsv = cv.cvtColor(im_hsv, cv.COLOR_HSV2BGR)\n",
    "    \n",
    "    ax.imshow(im_hsv)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Total area (in pixels) of each color\n",
    "Add your implementation and discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"area 1 = {stats[0][cv.CC_STAT_AREA]}\")\n",
    "print(f\"area 2 = {stats[1][cv.CC_STAT_AREA]}\")\n",
    "print(f\"proportion = {stats[0][cv.CC_STAT_AREA]/stats[1][cv.CC_STAT_AREA]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)\n",
    "\n",
    "dt = 0.01\n",
    "t = np.arange(0, 30, dt)\n",
    "nse1 = np.random.randn(len(t))                 # white noise 1\n",
    "nse2 = np.random.randn(len(t))                 # white noise 2\n",
    "\n",
    "# Two signals with a coherent part at 10Hz and a random part\n",
    "s1 = np.sin(2 * np.pi * 10 * t) + nse1\n",
    "s2 = np.sin(2 * np.pi * 10 * t) + nse2\n",
    "\n",
    "fig, axs = plt.subplots(2, 1)\n",
    "axs[0].plot(t, s1, t, s2)\n",
    "axs[0].set_xlim(0, 2)\n",
    "axs[0].set_xlabel('time')\n",
    "axs[0].set_ylabel('s1 and s2')\n",
    "axs[0].grid(True)\n",
    "\n",
    "cxy, f = axs[1].cohere(s1, s2, 256, 1. / dt)\n",
    "axs[1].set_ylabel('coherence')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
